<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="shortcut icon" href="favicon.ico" />
<link rel="bookmark" href="favicon.ico" type="image/x-icon"　/>
<title>Zhuoran Zhou</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Menu</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="https://github.com/xcharxlie">GitHub</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Zhuoran Zhou</h1>
</div>
<table class="imgtable"><tr><td>
<!-- <a href="https://xiuzezhou.github.io/"><img src="photos/bio.jpg" alt="alt text" width="131px" height="160px" /></a>&nbsp;</td> -->
<td align="left"><p><b>Research Assistant, </b> <br />
University of Washington, IPL Lab<br />
Seattle, WA <br />
E-mail: <a href="zhouz47@uw.edu">zhouz47@uw.edu</a></p>
</td></tr></table>
<h2>About me</h2>
<p>I received my B.S. degree and M.S. degree from the ECE department of the University of Washington, in 2021 and 2023 respectively. </br> I'm currently doing research at IPL Lab, UW, advised by Prof.Jenq-Neng Hwang. My main research areas are about Diffusion model and its application in 3D vision. Meanwhile, I'm also focusing on multi-modality feature learning in the relevant areas. </br> My reseach interests also include generation model, medical image and anything relevant to Computer Vision. </br> I love solving problems by developing models and algorithms in the area of Computer Vision. Though I was supposed to work as a full-time software engineer in the late 2023, after interning at Doordash and Amazon I decided to pursue a PhD degree instead as I am motivated to explore and work by my own will, as opposed to spending my precious time for the dreams of others. </p></p>


<h2>Research</h2>

<h3>Current work</h3>
<ul>
<li><p>Huamn Gaussian 3D splatting </p></li>
<li><p>Unified Motion Generation</p></li>
</ul>
<h3>Publication</h3>
<ol>
<li><p>Jiang, Z.*, <b>Zhou, Z.*</b>, Li, L., Chai, W., Yang, C. Y., & Hwang, J. N. (2023). Back to Optimization: Diffusion-based Zero-Shot 3D Human Pose Estimation. arXiv preprint arXiv:2307.03833. (*equal contribution)(WACV 2024)[<a href="https://arxiv.org/abs/2307.03833">arxiv</a>] [<a href="https://zhyjiang.github.io/ZeDO-proj/">project page</a>]
</p>
</li>
<li><p>Jin, Y., <b>Zhou, Z.</b>, Yang, Z., Wang, J., & Hwang. J. N. (2023). Latent Prompting Network for Controllable Radiology Report Generation. (In submission)</p>
</li>
<li><p>Jiang, Z., Chai, W., Li, L., <b>Zhou, Z.</b>, & Hwang, J. N.(2023). Towards Unified Human Pose Estimation via Contrastive Learning. (In submission)</p>
</li>
<li><p><b>Zhou, Z.</b>, Jiang, Z., Chai, W., Yang, C., & Hwang. J. N.(2023). Efficient Domain Adaptation via Generative Prior for 3D Infant Pose Estimation. (WACVW 2024)</p>
</li>
</ol>



<h2>Education</h2>
<p>M.S in Electrical & Computer Engineering,UW, Seattle, WA, 09.2021-03.2023</p>
<p>B.S in Electrical & Computer Engineering,UW, Seattle, WA, 09.2017-06.2021</p>

<h2>Research Experience</h2>
<ol>
<li><p><b>Research Assistant, Information Processing Lab, UW, Seattle, WA, 11.2022-Present</b></br></p></li>
<ul>
<li><p>Developed a human pose estimation optimization-based model which integrates a score matching diffusion model for iterative refinement to adjust coarse ray-projected 3D poses in the 2D-3D lifting task. Achieved zeros-shot SOTA performance even compared to deep-learning based models.</p>
</li>
<li><p>Transferred the idea of diffusion-refined pose estimation to the infant domain by efficient domain adaptation from the adult priors via a controllable branch and a condition-guided data augmentor.</p>
</li>
<li><p>Adopting CLIP’s visual-text understanding to bridge three modalities: point cloud, image and text through the integration of task-oriented prompt tuning in the point cloud downstreams.</p>
</li>
</ul>
<li><p><b>Part-Time Microsoft Azure Vision Research Intern, Seattle, WA, 01.2023-05.2023</b></p></li>
<ul>
<li><p>Established a classifier-guided DDPM Diffusion model trained by multiple symptom X-ray images to provide super-class pathology visual prompts to a VQVAE-based latent-prompt medical report generation model fine-tuned from GIT image captioning model and Llama. Disclosed disease-afflicted regions via anomaly map difference between healthy and diseased images generated by the diffusion model.</p>
</li>
<li><p>Integrated anomaly map tokens with learnable discrete latent prompts representing sentence-wise GMM pathology clusters to facilitate high-quality medical report generation, resulting in SOTA performance.
</p>
</li>
</ul>
<li><p><b>Undergrad Research Assistant, Information Processing Lab, UW, Seattle, WA, 08.2020-01.2021</b></p></li>
<ul>
<li><p>Cooperated with NOAA in labeling fish mask data and fine-tuning a Mask-RCNN based model, enhancing its ability of real-time fish species identification and instance segmentation within video footage.
</p>
</li>

</ul>
<li><p><b>Undergrad Research Assistant, Dr.Gire Lab Lab, UW, Seattle, WA, 06.2019-08.2019</b></p></li>
<ul>
<li><p>Simulated locomotion patterns of rats subjected to varying voltage levels and predicted the positions when rats became occluded using a Kalman Filter based model.</p>
</li>
<li><p>Applied the DeepLabCut model to keep track of multiple rats with bounding boxes in real time. </p>
</li>

</ul>
</ol>


<h2>Work Experience</h2>
<ol>
<li><p><b>Zongmu - Autonomous Driving Mobile Research Intern, Shanghai, 06.2021-09.2021</b></p></li>
<ul>
<li><p>Tuned a Detectron2 ABCNet model, facilitating recognition of vehicle plates and parking lot numbers with an accuracy of over 85% under severe occlusion and various brightness conditions.</p>
</li>
<li><p>Built an MQTT protocol-based network to transmit detection results to a cloud server which may reflect information on the mobile APP in less than 1.5 seconds. Additionally implemented an ONNX versioned model to support local execution on mobile devices.</p>
</li>

</ul>
<li><p><b>Telenav - Software Engineer Capstone Intern, Remote, 01.2021-06.2021</b></p></li>
<ul>
<li><p>Co-worked with Telenav Inc. in a group of three to develop a Java library to detect errors in the text queries transcribed from voice, and re-rank the queries by evaluating TF-IDF and n-gram correctness.</p>
</li>
<li><p>Designed and developed an Android App to deploy the testing library so that the new voice recognition system could tolerate accents and noisy environments.
</p>
</li>

</ul>
</ol>

<p><br />

<!-- <a href="cv/cv.pdf">my cv</a>. </p> -->
</td>
</tr>
</table>
</body>
</html>
