<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="shortcut icon" href="favicon.ico" />
<link rel="bookmark" href="favicon.ico" type="image/x-icon"　/>
<title>Zhuoran Zhou</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Menu</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="https://github.com/xcharxlie">GitHub</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Zhuoran Zhou</h1>
</div>
<table class="imgtable"><tr><td>
<!-- <a href="https://xiuzezhou.github.io/"><img src="photos/bio.jpg" alt="alt text" width="131px" height="160px" /></a>&nbsp;</td> -->
<td align="left"><p><b>Research Assistant, </b> <br />
University of Washington, IPL Lab<br />
Seattle, WA <br />
E-mail: <a href="zhouz47@uw.edu">zhouz47@uw.edu</a></p>
</td></tr></table>
<h2>About me</h2>
<p>I received my B.S. degree and M.S. degreee from the ECE department of the University of Washington, in 2021 and 2023 respectively. </br> I'm currently working as a research assistant at IPL Lab, UW. My main research area is about Diffusion model and its application in the area of Human Pose and Point Cloud. Meanwhile, I'm also focusing on multi-modality feature learning in the relevant areas. </br> My reseach interests also include generation model, medical image and anything relevant to Computer Vision. </br> I love solving practical problems with the power of AI. Though I was supposed to work as a full-time software engineer in the late 2023, after interning at Doordash and Amazon I decided to pursue a PhD degree instead as I prefer exploring and working by my own will, as opposed to spending my precious time for the dreams of others. </p></p>


<h2>Research</h2>

<h3>Current work</h3>
<ul>
<li><p>Point CLip++: Feature alignment across point cloud, image and text  </p></li>
<li><p>ZeDOv2 : Diffusion-based zero-shot 3d human pose estimation</p></li>
</ul>
<h3>Under review</h3>
<ol>
<li><p>Jiang, Z.*, <b>Zhou, Z.*</b>, Li, L., Chai, W., Yang, C. Y., & Hwang, J. N. (2023). Back to Optimization: Diffusion-based Zero-Shot 3D Human Pose Estimation. arXiv preprint arXiv:2307.03833. (*equal contribution)(Under Review WACV)[<a href="https://arxiv.org/pdf/2307.03833v2.pdf">pdf</a>]
</p>
</li>
<li><p>Jin, Y., <b>Zhou, Z.</b>, Yang, Z., Wang, J., & Hwang. J. N. (2023). Latent Prompting Network for Controllable Radiology Report Generation. (Under Review WACV)</p>
</li>
<li><p>Jiang, Z., Li, L., <b>Zhou, Z.</b>, Chai, W., Yang, C. Y., & Hwang, J. N.(2023). CPAE: Contrastive 2D-3D Pose Feature Alignment and Estimation.(Under Review WACV)</p>
</li>
</ol>

<!--
<li><p>Y. Ding, S. Jia, T. Ma*, B. Mao, <b>X. Zhou</b>, L. Liu, D. Han, and M. Chen, "Integrating Stock Features and Global Information via Large Language Models for Enhanced Stock Return Prediction", <i>In Proceedings of the 32nd International Joint Conference on Artificial Intelligence (IJCAI-23)</i>, Aug. 2023. </p>
</li>
<li><p>M. Chen, T. Ma, and <b>X. Zhou</b>*, "CoCNN: Co-occurrence CNN for Recommendation", <i>Expert Systems with Applications</i>, Jun. 2022, 195, pp. 116595. (IF = 8.665) [<a href="https://github.com/XiuzeZhou/cocnn">code</a>]</p>
</li>
<li><p>M. Chen, Y. Li, <b>X. Zhou</b>*, "CoNet: Co-occurrence Neural Networks for Recommendation", <i>Future Generation Computer Systems</i>, Nov. 2021, 124, pp. 308-314. (IF = 7.307) [<a href="https://github.com/XiuzeZhou/conet">code</a>]</p>
</li>
<li><p>M. Chen, <b>X. Zhou</b>*, "DeepRank: Learning to Rank with Neural Networks for Recommendation", <i>Knowledge-Based Systems</i>, Dec. 2020, 209, pp. 106478. (IF = 8.139) [<a href="https://github.com/XiuzeZhou/deeprank">code</a>]</p>
</li>
-->


<h2>Education</h2>
<p>M.S in Electrical & Computer Engineering,UW, Seattle, WA, 09.2021-03.2023</p>
<p>B.S in Electrical & Computer Engineering,UW, Seattle, WA, 09.2017-06.2021</p>

<h2>Research Experience</h2>
<ol>
<li><p><br>Research Assistant, Information Processing Lab, UW, Seattle, WA, 11.2022-Present</br></br></p></li>
<ul>
<li><p>Proposed and developed a human pose estimation optimization-based model which integrates a score matching diffusion model for iterative refinement to adjust coarse ray-projected 3D poses in the 2D-3D lifting task. Achieved zeros-shot SOTA performance even compared to deep-learning based models.</p>
</li>
<li><p>Constructed a contrastive-learning, transformer-based multimodal model which learns feature alignments among 2D pose, 3D pose via an innovative contrastive loss. So far achieved performance comparable to SOTA.</p>
</li>
<li><p>Transferred the idea of optimization-based diffusion-refined pipeline to face alignment and face mesh reconstruction tasks by elevating 2D detections and iteratively adjusting scales and positions of representative 3D face landmarks for better de-occlusion and mesh reconstruction effects.</p>
</li>
<li><p>Adopting CLIP’s visual-text understanding to bridge three modalities: point cloud, image and text through the integration of task-oriented prompt tuning in the point cloud downstreams.</p>
</li>
</ul>
<li><p><br>Microsoft Azure Vision Research Intern, Seattle, WA, 01.2023-07.2023</br></p></li>
<ul>
<li><p>Established a classifier-guided DDPM Diffusion model trained by multiple symptom X-ray images to provide super-class pathological information to a multi-round medical-use question-answering image captioning model fine-tuned from GIT.</p>
</li>
<li><p>Detected disease-afflicted regions via anomaly map difference between healthy and diseased images generated by the diffusion model. Appended anomaly map tokens to learned implicit latent prompts to facilitate medical report generation, resulting in SOTA performance.</p>
</li>
</ul>
<li><p><br>Undergrad Research Assistant, Information Processing Lab, UW, Seattle, WA, 08.2020-01.2021</br></p></li>
<ul>
<li><p>Cooperated with NOAA in labeling fish mask data and fine-tuning a Mask-RCNN based model, enhancing its ability of real-time fish species identification and instance segmentation within video footage.
</p>
</li>

</ul>
<li><p><br>Undergrad Research Assistant, Dr.Gire Lab Lab, UW, Seattle, WA, 06.2019-08.2019</br></p></li>
<ul>
<li><p>Simulated locomotion patterns of rats subjected to varying voltage levels and predicted the positions when rats became occluded using a Kalman Filter based model.</p>
</li>
<li><p>Applied the DeepLabCut model to keep track of multiple rats with bounding boxes in real time. </p>
</li>

</ul>
</ol>


<h2>Work Experience</h2>
<ol>
<li><p><br>Zongmu - Autonomous Driving Mobile Research Intern, Shanghai, 06.2021-09.2021</br></p></li>
<ul>
<li><p>Tuned a Detectron2 ABCNet model, facilitating recognition of vehicle plates and parking lot numbers with an accuracy of over 85% under severe occlusion and various brightness conditions.</p>
</li>
<li><p>Built an MQTT protocol-based network to transmit detection results to a cloud server which may reflect information on the mobile APP in less than 1.5 seconds. Additionally implemented an ONNX versioned model to support local execution on mobile devices.</p>
</li>

</ul>
<li><p><br>Telenav - Software Engineer Capstone Intern, Remote, 01.2021-06.2021</br></p></li>
<ul>
<li><p>Co-worked with Telenav Inc. in a group of three to develop a Java library to detect errors in the text queries transcribed from voice, and re-rank the queries by evaluating TF-IDF and n-gram correctness.</p>
</li>
<li><p>Designed and developed an Android App to deploy the testing library so that the new voice recognition system could tolerate accents and noisy environments.
</p>
</li>

</ul>
</ol>

<p><br />

<a href="cv/cv.pdf">cv</a>. </p>
</td>
</tr>
</table>
</body>
</html>
